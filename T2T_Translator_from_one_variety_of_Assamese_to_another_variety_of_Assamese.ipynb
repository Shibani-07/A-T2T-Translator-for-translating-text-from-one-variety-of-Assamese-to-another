{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ac0ulZN5ZCsT",
    "outputId": "ec2e28dd-4248-41db-8332-9d51b1c56beb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vowels: \n",
      "-------\n",
      "অ ax | আ aa | ই i | ঈ i | উ u | ঊ u | ঋ ri | এ e | ঐ oi | ও o | ঔ ou\n",
      "\n",
      "Consonants: \n",
      "-----------\n",
      "ক k | খ kh | গ g | ঘ gh | ঙ ng \n",
      "চ s | ছ s | জ j | ঝ jh | ঞ y \n",
      "-------------\n",
      "ট T | ঠ th | ড d | ঢ dh | ণ n \n",
      "ত t | থ th | দ d | ধ dh | ন n \n",
      "-------------\n",
      "প p | ফ ph | বb | ভ bh | ম m \n",
      "য j | ৰ r | ল l | ৱ w | শ x | ষ x \n",
      "-------------\n",
      "স x | হ h | ক্ষ khy | ড় r | ঢ় r | য় y | ৎ t\n",
      "\n",
      "Enter the std assamese sentence(using the transliterations above): jaabaxloi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jaabaxloi']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# In[23]:\n",
    "import string\n",
    "import re\n",
    "# In[24]:\n",
    "#Transliterations\n",
    "print(\"Vowels: \\n-------\\nঅ ax | আ aa | ই i | ঈ i | উ u | ঊ u | ঋ ri | এ e | ঐ oi | ও o | ঔ ou\\n\\nConsonants: \\n-----------\\nক k | খ kh | গ g | ঘ gh | ঙ ng \\nচ s | ছ s | জ j | ঝ jh | ঞ y \\n-------------\\nট T | ঠ th | ড d | ঢ dh | ণ n \\nত t | থ th | দ d | ধ dh | ন n \\n-------------\\nপ p | ফ ph | বb | ভ bh | ম m \\nয j | ৰ r | ল l | ৱ w | শ x | ষ x \\n-------------\\nস x | হ h | ক্ষ khy | ড় r | ঢ় r | য় y | ৎ t\")\n",
    "# In[25]:\n",
    "std_sen = input(\"\\nEnter the std assamese sentence(using the transliterations above): \")\n",
    "# In[26]:\n",
    "#Punctuation stripping\n",
    "std_sen = std_sen.translate(str.maketrans('', '', string.punctuation))\n",
    "#change the whole string into lowercase letters\n",
    "std_sen = std_sen.lower()\n",
    "# In[27]:\n",
    "#tokenise\n",
    "sen = std_sen.split(\" \");\n",
    "sen\n",
    "# In[28]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1lFKNRDZXX0D",
    "outputId": "651cfb09-6419-4e20-c301-d50f5d6464e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD AND ITS SUFFIX-->(Standard)  {'jaab': 'axloi'}\n"
     ]
    }
   ],
   "source": [
    "#-------Stemming--------\n",
    "#gather the data\n",
    "root_words = [line.rstrip() for line in open('assamese_rootwords.txt')]\n",
    "suffixes = [line.rstrip() for line in open('suffix.txt')]\n",
    "vowels = {'ax','aa','i','u','ri','e', 'oi', 'o', 'ou'}\n",
    "# In[29]:\n",
    "# Function to detect which suffix is attached\n",
    "def suffix_detection(word):\n",
    " lis = ['xxxx']\n",
    " maxm = 0\n",
    " for j in range(len(suffixes)):\n",
    "    if word.endswith(suffixes[j]) and len(suffixes[j]) > maxm:\n",
    "        maxm = len(suffixes[j])\n",
    "        lis[0] = suffixes[j] #add the prefix to the dictionary\n",
    "\n",
    "\n",
    "\n",
    " return lis\n",
    "# In[31]:\n",
    "#check whether the word given is alreasy a root word\n",
    "word = {} #dictionary to keep track of what suffixes are possible for the corresponding word\n",
    "for i in range(len(sen)):\n",
    " if sen[i] in root_words:\n",
    "  word[sen[i]] = 'None'\n",
    " else:\n",
    "  suffix = suffix_detection(sen[i])\n",
    "  root = sen[i].replace(suffix[0],'')\n",
    "  word[root] = suffix[0]\n",
    "print(\"WORD AND ITS SUFFIX-->(Standard) \",word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JPZTGq9ewrk"
   },
   "source": [
    "RULES **bold text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mFJwLxLPaGWu"
   },
   "outputs": [],
   "source": [
    "# In[33]:\n",
    "#using regular expression we will implement some rules\n",
    "def rule10(i):\n",
    " pattern = re.compile('(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|n|ph|p|bh|b|m|r|l|w|x|h|y)*(ax|aa|ri|i|u|e|oi|ou|o)+(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|n|ph|p|bh|b|m|r|l|w|x|h|y)+(ax)')\n",
    " x = re.findall(pattern, i)\n",
    " if not x:\n",
    "  return i\n",
    " index = i.rfind('ax')\n",
    " txt = i[:(index+1)] + 'a' + i[(index+2):]\n",
    " return txt \n",
    "\n",
    "\n",
    "# In[34]:\n",
    "def rule11(i):\n",
    " eleven = re.compile('(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|n|ph|p|bh|b|m|r|l|w|x|h|y)*(ax|aa|o)+(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|ph|n|p|bh|b|m|r|l|w|x|h|y)+(ax|aa|ri|i|u|e|oi|ou|o)+')\n",
    " x = re.findall(eleven,i)\n",
    " if not x:\n",
    "  return i\n",
    "\n",
    " if x[0][1] == 'ax':\n",
    "  index = i.find('ax')\n",
    "  txt = i[:(index)] + 'aa' + i[(index+2):]\n",
    " elif x[0][1] == 'o':\n",
    "  index = i.find('o')\n",
    "  txt = i[:(index)] + 'ax' + i[(index+1):]\n",
    "\n",
    " return txt\n",
    "\n",
    "# In[35]:\n",
    "def rule8(i):\n",
    " eight = re.compile('(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|n|ph|p|bh|b|m|r|l|w|x|h|y)*(ax|e)+(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|n|ph|p|bh|b|m|r|l|w|x|h|y)+(aa)')\n",
    " x = re.findall(eight, i)\n",
    " if not x:\n",
    "  return i\n",
    "\n",
    " if x[0][1] == 'ax':\n",
    "  index = i.find('ax')\n",
    "  txt = i[:(index)] + 'aa' + i[(index+2):]\n",
    " elif x[0][1] == 'e':\n",
    "  index = i.find('e')\n",
    "  txt = i[:(index)] + 'aa' + i[(index+1):]\n",
    "\n",
    " return txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "91vBTqUeb3F_"
   },
   "outputs": [],
   "source": [
    "# In[37]:\n",
    "def rule15(i):\n",
    " index = i.find('x')\n",
    " if index == -1:\n",
    "  return i\n",
    " if index == len(i) - 1:\n",
    "  txt = i[:(index)] + 'h'\n",
    " else:\n",
    "  txt = i[:(index)] + 'kh' + i[(index + 1):]\n",
    " return txt\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "def rule16(i):\n",
    " if (i.find(\"ax'\")) != -1:\n",
    "  i = i[:(index)] + 'o' + i[(index + 3):]\n",
    "  return i\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "def rule19(i):\n",
    " if i.endswith(('jaxn','jaxnaa','jaxni','gaxraaki')):\n",
    "  i = i.replace('jaxn','tu').replace('jaxnaa','tu').replace('jaxni','tu').replace('gaxraaki','tu')\n",
    "  return i\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "def rule25(i):\n",
    " if word[i].endswith('re'):\n",
    "  word[i] = word[i].replace('re','di')\n",
    "  i = i + word[i]\n",
    " return i\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "def rule23(i):\n",
    " if i.endswith(('le','ile')):\n",
    "  i = i.replace('le','laak').replace('ile','ilaak')\n",
    " return i\n",
    "\n",
    "\n",
    "# In[54]:\n",
    "def rule1(txt): #check\n",
    "  one = re.compile('(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|n|ph|p|bh|b|m|r|l|w|x|h|y)+(ax|aa|ri|i|u|e|oi|ou|o)+(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|n|ph|p|bh|b|m|r|l|w|x|h|y)+(ax|aa|ri|i|u|e|oi|ou|o)+(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|n|ph|p|bh|b|m|r|l|w|x|h|y)+(ax|aa|ri|i|u|e|oi|ou|o)+')\n",
    "  x = re.findall(one, txt)\n",
    "  if not x:\n",
    "    return txt\n",
    "  v = \"\"\n",
    "  for i in range(len(x[0])):\n",
    "    if i == 3:\n",
    "      continue\n",
    "    v = v + x[0][i]\n",
    "  return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AGq8wztKdGnY"
   },
   "outputs": [],
   "source": [
    "# In[43]:\n",
    "def rule12(i):\n",
    "  if i.startswith('ek'):\n",
    "    i = i.replace('ek','aak')\n",
    "  return i\n",
    "\n",
    "# In[44]:\n",
    "def rule17(txt):\n",
    " seventeen = re.compile('.*(ax|aa)(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|n|ph|p|bh|b|m|r|l|w|x|h|y)+(ax|aa|ri|i|u|e|oi|ou|o)+')\n",
    " x = re.findall(seventeen, txt)\n",
    " if not x:\n",
    "  return txt\n",
    " v = \"\"\n",
    " for i in range(len(x[0])):\n",
    "  v = v + x[0][i]\n",
    " if x[0][0] == 'ax':\n",
    "  txt = txt[:(txt.find(v))] + 'aa' + txt[(txt.find(v) + 2):]\n",
    " elif x[0][0] == 'aa':\n",
    "  txt = txt[:(txt.find(v))] + 'i' + txt[(txt.find(v) + 2):]\n",
    " return txt\n",
    "\n",
    "# In[45]:\n",
    "def rule18(i):\n",
    " if i.endswith(('bor','bilaal','hat','heten')):\n",
    "   i =i.replace('bor','gilaa').replace('bilaal','gilaal').replace('hat','hun').replace('heten','hoi')\n",
    " return i\n",
    "\n",
    "# In[46]:\n",
    "def rule5(txt):\n",
    " five =re.compile('.*(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|n|ph|p|bh|b|m|r|l|w|x|h|y)+(ax|aa|ri|i|u|e|oi|ou|o)+(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|n|ph|p|bh|b|m|r|l|w|x|h|y)+(ax|aa|ri|i|u|e|oi|ou|o)+')\n",
    " x = re.findall(five, txt)\n",
    " if not x:\n",
    "  return txt\n",
    "\n",
    " f = \"\"\n",
    " v = x[0][1]\n",
    " for i in range(len(x[0])):\n",
    "  f = f + x[0][i]\n",
    "  if i == 1:\n",
    "    continue;\n",
    "  v = v + x[0][i]\n",
    " txt = txt[:(txt.find(f))] + v\n",
    " return txt\n",
    "\n",
    "# In[89]:\n",
    "def rule13(i):\n",
    " thirteen =re.compile('.*(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|n|ph|p|bh|b|m|r|l|w|x|h|y)+(khy|kh|k|gh|g|ng|s|jh|j|y|th|t|dh|d|n|ph|p|bh|b|m|r|l|w|x|h|y)+(ax)$')\n",
    " x = re.findall(thirteen,i)\n",
    " if not x:\n",
    "  return False\n",
    " else:\n",
    "  return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "44k8BA23ee1g",
    "outputId": "ed07a376-4f04-411f-c1ab-8beb5485924e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MAPPED WORDS-->  {'jaab': 'jaabaaklegi'}\n",
      "\n",
      "NALBARIA SENTENCE: \n",
      "jaabaaklegi  "
     ]
    }
   ],
   "source": [
    "# In[62]:\n",
    "# -------- mapping ---------#\n",
    "# will implement sets and dictionary so that when membership operator 'in'\n",
    "# is used the average search time is O(1)\n",
    "mapped = {} #keeping the mapped words in this dictionary\n",
    "#implementing rule 9 and 10\n",
    "do_not_change = {'saabi', 'prithibi', 'soukaa', 'gaxru', 'kaali','dilu'}\n",
    "change_completely ={'kaxkaa':'aataa','aaitaa':'aabu','dhuniyaa':'thougaa','tirotaa':'tiri','maxtaa':'maxraxd','baacchaa':'soli','baxraxxun':'boirhaan','jaxlaxkiyaa':'bhaxjluk','laxraa':'aapaa','pelaai':'phele','haxnkraanti':'domahi','gaxraxm':'taxpaxt','nigaxni':'ningni','bhaxraal':'bhaakhri','xaxru':'saanaa','daangaxr':'dhumaa','hihaxtaxr':'taahaar','eraal':'daxraxkh','suwaali':'aapi','nangaxl':'langaxl','leseraa':'neseraa','lon':'nun','nowaarilo':'nollu', 'kaxrile':'kaxille','nowaaro':'nuoru','paarilo':'paaillu','xorir':'xoril'}\n",
    "#checking if root words belong to either of above two lists of words\n",
    "for i in word:\n",
    " if i in do_not_change:\n",
    "  mapped[i] = i\n",
    " elif i in change_completely:\n",
    "  mapped[i] = change_completely[i]\n",
    " elif word[i] == 'axloi': # rule 6\n",
    "  mapped[i] = i + 'aaklegi'\n",
    " elif word[i] == 'oi' or word[i] == 'ou':#rule 9\n",
    "  mapped[i] = i + ('ou' if word[i][0] == 'ou' else 'oi')\n",
    " elif (i != (r := rule10(i))):\n",
    "  mapped[i] = r\n",
    " elif (i != (r := rule11(i))):\n",
    "  mapped[i] = r\n",
    " elif (i != (r := rule8(i))):\n",
    "  mapped[i] = r\n",
    " elif (i != (r := rule15(i))):\n",
    "  mapped[i] = r\n",
    " elif (i != (r := rule16(i))):\n",
    "  mapped[i] = r\n",
    " elif (i != (r := rule19(i))):\n",
    "  mapped[i] = r\n",
    " elif (i != (r := rule25(i))):\n",
    "  mapped[i] = r\n",
    " elif (i != (r := rule23(i))):\n",
    "  mapped[i] = r\n",
    " elif (i != (r := rule1(i))):\n",
    "  mapped[i] = r\n",
    " elif (i != (r := rule12(i))):\n",
    "  mapped[i] = r\n",
    " elif (i != (r := rule17(i))):\n",
    "  mapped[i] = r\n",
    " elif (i != (r := rule18(i))):\n",
    "  mapped[i] = r\n",
    " elif (i != (r := rule5(i))):\n",
    "  mapped[i] = r\n",
    " elif rule13(i):\n",
    "  mapped[i] = i[:(len(i) - 2)] + 'o'\n",
    " else:\n",
    "  if word[i] == 'None':\n",
    "    mapped[i] = i\n",
    "  else:\n",
    "    mapped[i] = i + word[i]\n",
    " \n",
    "print(\"\\nMAPPED WORDS--> \", mapped)\n",
    "\n",
    "print(\"\\nNALBARIA SENTENCE: \")\n",
    "for i in mapped:\n",
    " print(mapped[i],' ',end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62gqYzuii4DY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
